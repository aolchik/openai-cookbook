{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30995a82",
   "metadata": {},
   "source": [
    "# How to build a tool-using agent with LangChain\n",
    "\n",
    "This notebook takes you through how to use LangChain to augment an OpenAI model with access to external tools. In particular, you'll be able to create LLM agents that use custom tools to answer user queries.\n",
    "\n",
    "\n",
    "## What is Langchain?\n",
    "[LangChain](https://python.langchain.com/en/latest/index.html) is a framework for developing applications powered by language models. Their framework enables you to build layered LLM-powered applications that are context-aware and able to interact dynamically with their environment as agents, leading to simplified code for you and a more dynamic user experience for your customers.\n",
    "\n",
    "## Why do LLMs need to use Tools?\n",
    "One of the most common challenges with LLMs is overcoming the lack of recency and specificity in their training data - answers can be out of date, and they are prone to hallucinations given the huge variety in their knowledge base. Tools are a great method of allowing an LLM to answer within a controlled context that draws on your existing knowledge bases and internal APIs - instead of trying to prompt engineer the LLM all the way to your intended answer, you allow it access to tools that it calls on dynamically for info, parses, and serves to customer. \n",
    "\n",
    "Providing LLMs access to tools can enable them to answer questions with context directly from search engines, APIs or your own databases. Instead of answering directly, an LLM with access to tools can perform intermediate steps to gather relevant information. Tools can also be used in combination. [For example](https://python.langchain.com/en/latest/modules/agents/agents/examples/mrkl_chat.html), a language model can be made to use a search tool to lookup quantitative information and a calculator to execute calculations.\n",
    "\n",
    "## Notebook Sections\n",
    "\n",
    "- **Setup:** Import packages and connect to a Pinecone vector database.\n",
    "- **LLM Agent:** Build an agent that leverages a modified version of the [ReAct](https://react-lm.github.io/) framework to do chain-of-thought reasoning.\n",
    "- **LLM Agent with History:** Provide the LLM with access to previous steps in the conversation.\n",
    "- **Knowledge Base:** Create a knowledge base of \"Stuff You Should Know\" podcast episodes, to be accessed through a tool.\n",
    "- **LLM Agent with Tools:** Extend the agent with access to multiple tools and test that it uses them to answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c069980",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a254003",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Import libraries and set up a connection to a [Pinecone](https://www.pinecone.io) vector database.\n",
    "\n",
    "You can substitute Pinecone for any other vectorstore or database - there are a [selection](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html) that are supported by Langchain natively, while other connectors will need to be developed yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55905f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install pinecone-client\n",
    "# !pip install pandas\n",
    "# !pip install typing\n",
    "# !pip install tqdm\n",
    "# !pip install langchain\n",
    "# !pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18be3d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Union\n",
    "import zipfile\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import BaseChatPromptTemplate, ChatPromptTemplate\n",
    "from langchain import SerpAPIWrapper, LLMChain\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage, SystemMessage\n",
    "# LLM wrapper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import OpenAI\n",
    "# Conversational memory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "# Embeddings and vectorstore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# Vectorstore Index\n",
    "index_name = 'podcasts'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c85f298",
   "metadata": {},
   "source": [
    "For acquiring an API key to connect with Pinecone, you can set up a [free account](https://app.pinecone.io/) and store it in the `api_key` variable below or in your environment variables under `PINECONE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af825644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pinecone environment: asia-northeast1-gcp\n",
      "Using Pinecode API Key: 4112fb51-d5b8-4288-b289-a89aebf10d74\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"PINECONE_API_KEY\") or \"PINECONE_API_KEY\"\n",
    "\n",
    "# find environment next to your API key in the Pinecone console\n",
    "env = os.getenv(\"PINECONE_ENVIRONMENT\") or \"PINECONE_ENVIRONMENT\"\n",
    "\n",
    "print(f\"Using Pinecone environment: {env}\")\n",
    "print(f\"Using Pinecode API Key: {api_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20f28939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhoAmIResponse(username='3aae44b', user_label='default', projectname='5211ec9')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#api_key=\"4112fb51-d5b8-4288-b289-a89aebf10d74\"\n",
    "#env=\"asia-northeast1-gcp\"\n",
    "pinecone.init(api_key=api_key, environment=env)\n",
    "pinecone.whoami()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0518596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['podcasts']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7644cd",
   "metadata": {},
   "source": [
    "Run this code block if you want to clear the index, or if the index doesn't exist yet\n",
    "\n",
    "```\n",
    "# Check whether the index with the same name already exists - if so, delete it\n",
    "if index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(index_name)\n",
    "    \n",
    "# Creates new index\n",
    "pinecone.create_index(name=index_name, dimension=1536)\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "# Confirm our index was created\n",
    "pinecone.list_indexes()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb63e37",
   "metadata": {},
   "source": [
    "## LLM Agent\n",
    "\n",
    "An [LLM agent](https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_agent.html) in Langchain has many configurable components, which are detailed in the Langchain documentation.\n",
    "\n",
    "We'll employ a few of the core concepts to make an agent that talks in the way we want, can use tools to answer questions, and uses the appropriate language model to power the conversation.\n",
    "- **Prompt Template:** The input template to control the LLM's behaviour and how it accepts inputs and produces outputs - this is the brain that drives your application ([docs](https://python.langchain.com/en/latest/modules/prompts/prompt_templates.html)).\n",
    "- **Output Parser:** A method of parsing the output from the prompt. If the LLM produces output using certain headers, you can enable complex interactions where variables are generated by the LLM in their response and passed into the next step of the chain ([docs](https://python.langchain.com/en/latest/modules/prompts/output_parsers.html)).\n",
    "- **LLM Chain:** A Chain brings together a prompt template with an LLM that will execute it - in this case we'll be using ```gpt-3.5-turbo``` but this framework can be used with OpenAI completions models, or other LLMs entirely ([docs](https://python.langchain.com/en/latest/modules/chains.html)).\n",
    "- **Tool:** An external service that the LLM can use to retrieve information or execute commands should the user require it ([docs](https://python.langchain.com/en/latest/modules/agents/tools.html)).\n",
    "- **Agent:** The glue that brings all of this together, an agent can call multiple LLM Chains, each with their own tools. Agents can be extended with your own logic to allow retries, error handling and any other methods you choose to add reliability to your application ([docs](https://python.langchain.com/en/latest/modules/agents.html)).\n",
    "\n",
    "**NB:** Before using this cookbook with the Search tool you'll need to sign up on https://serpapi.com/ and generate an API key. Once you have it, store it in an environment variable named ```SERPAPI_API_KEY```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ab2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend SerpAPIWrapper to log input and output of run\n",
    "class CustomSerpAPIWrapper(SerpAPIWrapper):\n",
    "    def run(self, query: str, n: int = 10, **kwargs) -> List[str]:\n",
    "        print(\"\\n\\t# SerpAPIWrapper.run started\")\n",
    "        print(f\"\\n\\t## Query: {query}\")\n",
    "        results = super().run(query=query, n=n, **kwargs)\n",
    "        results_str = re.sub(r\"(\\[\\'|\\'\\]|\\', \\')\", \"\\n\\n\\t\\t\", str(results))\n",
    "        # add an additional line break at 80 character longs if line is longer without breaking words\n",
    "        results_str = re.sub(r\"\\b(.{50}\\S*)\\b\", r\"\\1\\n\\t\\t\", results_str)\n",
    "        \n",
    "        print(f\"\\n\\t## Results: {results_str}\")\n",
    "        print(\"\\n\\t# SerpAPIWrapper.run finished\\n\\n\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f813668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a Search tool - note you'll need to have set SERPAPI_API_KEY as an environment variable as per the above instructions\n",
    "search = CustomSerpAPIWrapper()\n",
    "\n",
    "# Define a list of tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effae642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the prompt with input variables for tools, user input and a scratchpad for the model to record its workings\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. \n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4efd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        \n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "            \n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        \n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        \n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "    \n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "533657a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        \n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        \n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        \n",
    "        # If it can't parse the output it raises an error\n",
    "        # You can add your own logic here to handle errors in a different way i.e. pass to a human, give a canned response\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        \n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "    \n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b61259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Any,\n",
    "    List,\n",
    "    Optional\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import BaseMessage, ChatResult\n",
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "\n",
    "# Create wrapper for ChatOpenAI to log input and output\n",
    "class CustomChatOpenAI(ChatOpenAI):\n",
    "    def _generate(self, \n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        print(\"\\n\\t# CustomChatOpenAi._generate started\")\n",
    "        messages_str = [json.dumps(message.dict(), indent=2) for message in messages]\n",
    "        messages_str = \"\\n\\t\".join(messages_str)\n",
    "        messages_str = messages_str.replace(\"\\\\n\", \"\\n\")\n",
    "        messages_str = \"\\n\\t\".join(messages_str.split(\"\\n\"))\n",
    "        print(f\"\\n\\t\\t## Messages: \\n\\t\\t{messages_str}\")\n",
    "\n",
    "        result = super()._generate(messages=messages, stop=stop, run_manager=run_manager, stream=stream, **kwargs)\n",
    "        result_str = json.dumps(result.dict(), indent=2)\n",
    "        result_str = result_str.replace(\"\\\\n\", \"\\n\")\n",
    "        result_str = \"\\n\\t\".join(result_str.split(\"\\n\"))         \n",
    "        print(f\"\\n\\t## Result: \\n\\t{result_str}\")\n",
    "        \n",
    "        print(\"\\n\\t# CustomChatOpenAi._generate finished\\n\\n\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7d93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate our LLM - default is 'gpt-3.5-turbo'\n",
    "llm = CustomChatOpenAI(temperature=0, verbose=True)\n",
    "\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Using tools, the LLM chain and output_parser to make an agent\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    # We use \"Observation\" as our stop sequence so it will stop when it receives Tool output\n",
    "    # If you change your prompt template you'll need to adjust this as well\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd893fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the agent that will respond to our queries\n",
    "# Set verbose=True to share the CoT reasoning the LLM goes through\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ca3ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"Answer the following questions as best you can, but speaking as a pirate might speak. \n",
      "\tYou have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to speak as a pirate when giving your final answer. Use lots of \\\"Arg\\\"s\n",
      "\t\n",
      "\tQuestion: How many people live in canada as of 2023?\n",
      "\t\",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Thought: I be needin' to find out how many people be livin' in Canada in 2023.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"Population of Canada in 2023\\\"\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Thought: I be needin' to find out how many people be livin' in Canada in 2023.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"Population of Canada in 2023\\\"\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 40,\n",
      "\t      \"prompt_tokens\": 177,\n",
      "\t      \"total_tokens\": 217\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThought: I be needin' to find out how many people be livin' in Canada in 2023.\n",
      "Action: Search\n",
      "Action Input: \"Population of Canada in 2023\"\u001b[0m\n",
      "\t# SerpAPIWrapper.run started\n",
      "\n",
      "\t## Query: Population of Canada in 2023\n",
      "\n",
      "\t## Results: 40 million Canadians\n",
      "\n",
      "\t# SerpAPIWrapper.run finished\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m40 million Canadians\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"Answer the following questions as best you can, but speaking as a pirate might speak. \n",
      "\tYou have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to speak as a pirate when giving your final answer. Use lots of \\\"Arg\\\"s\n",
      "\t\n",
      "\tQuestion: How many people live in canada as of 2023?\n",
      "\tThought: I be needin' to find out how many people be livin' in Canada in 2023.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"Population of Canada in 2023\\\"\n",
      "\tObservation: 40 million Canadians\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"I now know the final answer\n",
      "\tFinal Answer: Arg, there be 40 million Canadians in Canada as of 2023.\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"I now know the final answer\n",
      "\tFinal Answer: Arg, there be 40 million Canadians in Canada as of 2023.\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 26,\n",
      "\t      \"prompt_tokens\": 228,\n",
      "\t      \"total_tokens\": 254\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Arg, there be 40 million Canadians in Canada as of 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Arg, there be 40 million Canadians in Canada as of 2023.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff96040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"Answer the following questions as best you can, but speaking as a pirate might speak. \n",
      "\tYou have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to speak as a pirate when giving your final answer. Use lots of \\\"Arg\\\"s\n",
      "\t\n",
      "\tQuestion: How many in 2022?\n",
      "\t\",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Thought: I need to find out how many of what in 2022?\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"How many in 2022?\\\"\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Thought: I need to find out how many of what in 2022?\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"How many in 2022?\\\"\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 31,\n",
      "\t      \"prompt_tokens\": 172,\n",
      "\t      \"total_tokens\": 203\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out how many of what in 2022?\n",
      "Action: Search\n",
      "Action Input: \"How many in 2022?\"\u001b[0m\n",
      "\t# SerpAPIWrapper.run started\n",
      "\n",
      "\t## Query: How many in 2022?\n",
      "\n",
      "\t## Results: \n",
      "\n",
      "\t\tThe year 2022 has 365 days. « day numbers for 2021\n",
      "\t\t | day numbers for 2023 ». Date, Day number, Days remaining\n",
      "\t\t ...\n",
      "\n",
      "\t\tThe World Population in 2023 is 8,045,311,447 (at mid-year\n",
      "\t\t, according to U.N. estimates), a 0.88% increase (70,206,291\n",
      "\t\t people) from 2022, when the population ...\n",
      "\n",
      "\t\tAll days 2022: dates, weekdays, day numbers, days left\n",
      "\t\t, and week numbers ; March 16, 2022, Wednesday, Day\n",
      "\t\t 75 ; March 17, 2022, Thursday, Day 76 ; March 18, 2022\n",
      "\t\t ...', \"The projected world population on Jan. 1, 2022\n",
      "\t\t is 7,868,872,451, an increase of 74,235,487, or 0.95\n",
      "\t\t%, from New Year's Day 2021. During January ...\", 'The\n",
      "\t\t world population reached eight billion people in 2022\n",
      "\t\t, though the year ... many countries. 21 July. The\n",
      "\t\t Parliament of Sri Lanka elects Prime ...\n",
      "\n",
      "\t\tPopulation, 2022, Pop. per sq. mi., 2022. Guttenberg\n",
      "\t\t town, NJ, 11,446, 59,305.7. West New York town, NJ\n",
      "\t\t, 51,981, 52,294.8. Union City city, NJ, 65,366, 50,789.4\n",
      "\t\t.', \"The projected world population on Jan. 1, 2022\n",
      "\t\t is 7,868,872,451, an increase of 74,235,487, or 0.95\n",
      "\t\t%, from New Year's Day 2021. During ...\", 'Day numbers\n",
      "\t\t 2022 ; 108 · 109 · 110 ; April 18 · April 19 · April\n",
      "\t\t 20 ; Monday · Tuesday · Wednesday ...\n",
      "\n",
      "\t\tThe year 2022 is a common year, with 365 days in total\n",
      "\t\t. Calendar type: Gregorian calendar. Tools. Years with\n",
      "\t\t Same Calendar as 2022. Customization Forms.\n",
      "\n",
      "\t\tThis is the 2022–23 school year calendar for all 3K–12\n",
      "\t\t NYCDOE public schools. If your child attends a private\n",
      "\t\t, parochial, charter school, NYCEEC Early Childhood\n",
      "\t\t ...\n",
      "\n",
      "\t\t\n",
      "\n",
      "\t# SerpAPIWrapper.run finished\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m['The year 2022 has 365 days. « day numbers for 2021 | day numbers for 2023 ». Date, Day number, Days remaining ...', 'The World Population in 2023 is 8,045,311,447 (at mid-year, according to U.N. estimates), a 0.88% increase (70,206,291 people) from 2022, when the population ...', 'All days 2022: dates, weekdays, day numbers, days left, and week numbers ; March 16, 2022, Wednesday, Day 75 ; March 17, 2022, Thursday, Day 76 ; March 18, 2022 ...', \"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During January ...\", 'The world population reached eight billion people in 2022, though the year ... many countries. 21 July. The Parliament of Sri Lanka elects Prime ...', 'Population, 2022, Pop. per sq. mi., 2022. Guttenberg town, NJ, 11,446, 59,305.7. West New York town, NJ, 51,981, 52,294.8. Union City city, NJ, 65,366, 50,789.4.', \"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During ...\", 'Day numbers 2022 ; 108 · 109 · 110 ; April 18 · April 19 · April 20 ; Monday · Tuesday · Wednesday ...', 'The year 2022 is a common year, with 365 days in total. Calendar type: Gregorian calendar. Tools. Years with Same Calendar as 2022. Customization Forms.', 'This is the 2022–23 school year calendar for all 3K–12 NYCDOE public schools. If your child attends a private, parochial, charter school, NYCEEC Early Childhood ...']\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"Answer the following questions as best you can, but speaking as a pirate might speak. \n",
      "\tYou have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to speak as a pirate when giving your final answer. Use lots of \\\"Arg\\\"s\n",
      "\t\n",
      "\tQuestion: How many in 2022?\n",
      "\tThought: I need to find out how many of what in 2022?\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"How many in 2022?\\\"\n",
      "\tObservation: ['The year 2022 has 365 days. \\u00ab day numbers for 2021 | day numbers for 2023 \\u00bb. Date, Day number, Days remaining ...', 'The World Population in 2023 is 8,045,311,447 (at mid-year, according to U.N. estimates), a 0.88% increase (70,206,291 people) from 2022, when the population ...', 'All days 2022: dates, weekdays, day numbers, days left, and week numbers ; March 16, 2022, Wednesday, Day 75 ; March 17, 2022, Thursday, Day 76 ; March 18, 2022 ...', \\\"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During January ...\\\", 'The world population reached eight billion people in 2022, though the year ... many countries. 21 July. The Parliament of Sri Lanka elects Prime ...', 'Population, 2022, Pop. per sq. mi., 2022. Guttenberg town, NJ, 11,446, 59,305.7. West New York town, NJ, 51,981, 52,294.8. Union City city, NJ, 65,366, 50,789.4.', \\\"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During ...\\\", 'Day numbers 2022 ; 108 \\u00b7 109 \\u00b7 110 ; April 18 \\u00b7 April 19 \\u00b7 April 20 ; Monday \\u00b7 Tuesday \\u00b7 Wednesday ...', 'The year 2022 is a common year, with 365 days in total. Calendar type: Gregorian calendar. Tools. Years with Same Calendar as 2022. Customization Forms.', 'This is the 2022\\u201323 school year calendar for all 3K\\u201312 NYCDOE public schools. If your child attends a private, parochial, charter school, NYCEEC Early Childhood ...']\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"I need to find out how many of what in 2022?\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"How many in 2022?\\\"\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"I need to find out how many of what in 2022?\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"How many in 2022?\\\"\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 29,\n",
      "\t      \"prompt_tokens\": 690,\n",
      "\t      \"total_tokens\": 719\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mI need to find out how many of what in 2022?\n",
      "Action: Search\n",
      "Action Input: \"How many in 2022?\"\u001b[0m\n",
      "\t# SerpAPIWrapper.run started\n",
      "\n",
      "\t## Query: How many in 2022?\n",
      "\n",
      "\t## Results: \n",
      "\n",
      "\t\tThe year 2022 has 365 days. « day numbers for 2021\n",
      "\t\t | day numbers for 2023 ». Date, Day number, Days remaining\n",
      "\t\t ...\n",
      "\n",
      "\t\tThe World Population in 2023 is 8,045,311,447 (at mid-year\n",
      "\t\t, according to U.N. estimates), a 0.88% increase (70,206,291\n",
      "\t\t people) from 2022, when the population ...\n",
      "\n",
      "\t\tAll days 2022: dates, weekdays, day numbers, days left\n",
      "\t\t, and week numbers ; March 16, 2022, Wednesday, Day\n",
      "\t\t 75 ; March 17, 2022, Thursday, Day 76 ; March 18, 2022\n",
      "\t\t ...', \"The projected world population on Jan. 1, 2022\n",
      "\t\t is 7,868,872,451, an increase of 74,235,487, or 0.95\n",
      "\t\t%, from New Year's Day 2021. During January ...\", 'The\n",
      "\t\t world population reached eight billion people in 2022\n",
      "\t\t, though the year ... many countries. 21 July. The\n",
      "\t\t Parliament of Sri Lanka elects Prime ...\n",
      "\n",
      "\t\tPopulation, 2022, Pop. per sq. mi., 2022. Guttenberg\n",
      "\t\t town, NJ, 11,446, 59,305.7. West New York town, NJ\n",
      "\t\t, 51,981, 52,294.8. Union City city, NJ, 65,366, 50,789.4\n",
      "\t\t.', \"The projected world population on Jan. 1, 2022\n",
      "\t\t is 7,868,872,451, an increase of 74,235,487, or 0.95\n",
      "\t\t%, from New Year's Day 2021. During ...\", 'Day numbers\n",
      "\t\t 2022 ; 108 · 109 · 110 ; April 18 · April 19 · April\n",
      "\t\t 20 ; Monday · Tuesday · Wednesday ...\n",
      "\n",
      "\t\tThe year 2022 is a common year, with 365 days in total\n",
      "\t\t. Calendar type: Gregorian calendar. Tools. Years with\n",
      "\t\t Same Calendar as 2022. Customization Forms.\n",
      "\n",
      "\t\tThis is the 2022–23 school year calendar for all 3K–12\n",
      "\t\t NYCDOE public schools. If your child attends a private\n",
      "\t\t, parochial, charter school, NYCEEC Early Childhood\n",
      "\t\t ...\n",
      "\n",
      "\t\t\n",
      "\n",
      "\t# SerpAPIWrapper.run finished\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m['The year 2022 has 365 days. « day numbers for 2021 | day numbers for 2023 ». Date, Day number, Days remaining ...', 'The World Population in 2023 is 8,045,311,447 (at mid-year, according to U.N. estimates), a 0.88% increase (70,206,291 people) from 2022, when the population ...', 'All days 2022: dates, weekdays, day numbers, days left, and week numbers ; March 16, 2022, Wednesday, Day 75 ; March 17, 2022, Thursday, Day 76 ; March 18, 2022 ...', \"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During January ...\", 'The world population reached eight billion people in 2022, though the year ... many countries. 21 July. The Parliament of Sri Lanka elects Prime ...', 'Population, 2022, Pop. per sq. mi., 2022. Guttenberg town, NJ, 11,446, 59,305.7. West New York town, NJ, 51,981, 52,294.8. Union City city, NJ, 65,366, 50,789.4.', \"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During ...\", 'Day numbers 2022 ; 108 · 109 · 110 ; April 18 · April 19 · April 20 ; Monday · Tuesday · Wednesday ...', 'The year 2022 is a common year, with 365 days in total. Calendar type: Gregorian calendar. Tools. Years with Same Calendar as 2022. Customization Forms.', 'This is the 2022–23 school year calendar for all 3K–12 NYCDOE public schools. If your child attends a private, parochial, charter school, NYCEEC Early Childhood ...']\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"Answer the following questions as best you can, but speaking as a pirate might speak. \n",
      "\tYou have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to speak as a pirate when giving your final answer. Use lots of \\\"Arg\\\"s\n",
      "\t\n",
      "\tQuestion: How many in 2022?\n",
      "\tThought: I need to find out how many of what in 2022?\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"How many in 2022?\\\"\n",
      "\tObservation: ['The year 2022 has 365 days. \\u00ab day numbers for 2021 | day numbers for 2023 \\u00bb. Date, Day number, Days remaining ...', 'The World Population in 2023 is 8,045,311,447 (at mid-year, according to U.N. estimates), a 0.88% increase (70,206,291 people) from 2022, when the population ...', 'All days 2022: dates, weekdays, day numbers, days left, and week numbers ; March 16, 2022, Wednesday, Day 75 ; March 17, 2022, Thursday, Day 76 ; March 18, 2022 ...', \\\"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During January ...\\\", 'The world population reached eight billion people in 2022, though the year ... many countries. 21 July. The Parliament of Sri Lanka elects Prime ...', 'Population, 2022, Pop. per sq. mi., 2022. Guttenberg town, NJ, 11,446, 59,305.7. West New York town, NJ, 51,981, 52,294.8. Union City city, NJ, 65,366, 50,789.4.', \\\"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During ...\\\", 'Day numbers 2022 ; 108 \\u00b7 109 \\u00b7 110 ; April 18 \\u00b7 April 19 \\u00b7 April 20 ; Monday \\u00b7 Tuesday \\u00b7 Wednesday ...', 'The year 2022 is a common year, with 365 days in total. Calendar type: Gregorian calendar. Tools. Years with Same Calendar as 2022. Customization Forms.', 'This is the 2022\\u201323 school year calendar for all 3K\\u201312 NYCDOE public schools. If your child attends a private, parochial, charter school, NYCEEC Early Childhood ...']\n",
      "\tThought: I need to find out how many of what in 2022?\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"How many in 2022?\\\"\n",
      "\tObservation: ['The year 2022 has 365 days. \\u00ab day numbers for 2021 | day numbers for 2023 \\u00bb. Date, Day number, Days remaining ...', 'The World Population in 2023 is 8,045,311,447 (at mid-year, according to U.N. estimates), a 0.88% increase (70,206,291 people) from 2022, when the population ...', 'All days 2022: dates, weekdays, day numbers, days left, and week numbers ; March 16, 2022, Wednesday, Day 75 ; March 17, 2022, Thursday, Day 76 ; March 18, 2022 ...', \\\"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During January ...\\\", 'The world population reached eight billion people in 2022, though the year ... many countries. 21 July. The Parliament of Sri Lanka elects Prime ...', 'Population, 2022, Pop. per sq. mi., 2022. Guttenberg town, NJ, 11,446, 59,305.7. West New York town, NJ, 51,981, 52,294.8. Union City city, NJ, 65,366, 50,789.4.', \\\"The projected world population on Jan. 1, 2022 is 7,868,872,451, an increase of 74,235,487, or 0.95%, from New Year's Day 2021. During ...\\\", 'Day numbers 2022 ; 108 \\u00b7 109 \\u00b7 110 ; April 18 \\u00b7 April 19 \\u00b7 April 20 ; Monday \\u00b7 Tuesday \\u00b7 Wednesday ...', 'The year 2022 is a common year, with 365 days in total. Calendar type: Gregorian calendar. Tools. Years with Same Calendar as 2022. Customization Forms.', 'This is the 2022\\u201323 school year calendar for all 3K\\u201312 NYCDOE public schools. If your child attends a private, parochial, charter school, NYCEEC Early Childhood ...']\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"I now know the final answer\n",
      "\tFinal Answer: Arrr, the year 2022 has 365 days, matey!\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"I now know the final answer\n",
      "\tFinal Answer: Arrr, the year 2022 has 365 days, matey!\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 26,\n",
      "\t      \"prompt_tokens\": 1205,\n",
      "\t      \"total_tokens\": 1231\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Arrr, the year 2022 has 365 days, matey!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Arrr, the year 2022 has 365 days, matey!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many in 2022?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b51817",
   "metadata": {},
   "source": [
    "## LLM Agent with History\n",
    "\n",
    "Extend the LLM Agent with the ability to retain a [memory](https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_agent.html#adding-memory) and use it as context as it continues the conversation.\n",
    "\n",
    "We use a simple ```ConversationBufferWindowMemory``` for this example that keeps a rolling window of the last two conversation turns. LangChain has other [memory options](https://python.langchain.com/en/latest/modules/memory.html), with different tradeoffs suitable for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85737eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template which can interpolate the history\n",
    "template_with_history = \"\"\"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to give detailed, informative answers\n",
    "\n",
    "Previous conversation history:\n",
    "{history}\n",
    "\n",
    "New question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d85c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=tools,\n",
    "    # The history template includes \"history\" as an input variable so we can interpolate it into the prompt\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f8c8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the memory with k=2 to keep the last two turns\n",
    "# Provide the memory to the agent\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1f031bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\t\n",
      "\t\n",
      "\tNew question: How many people live in canada as of 2023?\n",
      "\t\",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Thought: I need to find the current population of Canada as of 2023.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"current population of Canada 2023\\\"\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Thought: I need to find the current population of Canada as of 2023.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"current population of Canada 2023\\\"\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 33,\n",
      "\t      \"prompt_tokens\": 180,\n",
      "\t      \"total_tokens\": 213\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the current population of Canada as of 2023.\n",
      "Action: Search\n",
      "Action Input: \"current population of Canada 2023\"\u001b[0m\n",
      "\t# SerpAPIWrapper.run started\n",
      "\n",
      "\t## Query: current population of Canada 2023\n",
      "\n",
      "\t## Results: Canada ranks 37th by population among countries of\n",
      "\t\t the world, comprising about 0.5% of the world's total\n",
      "\t\t, with 40 million Canadians as of 2023.\n",
      "\n",
      "\t# SerpAPIWrapper.run finished\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mCanada ranks 37th by population among countries of the world, comprising about 0.5% of the world's total, with 40 million Canadians as of 2023.\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\t\n",
      "\t\n",
      "\tNew question: How many people live in canada as of 2023?\n",
      "\tThought: I need to find the current population of Canada as of 2023.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"current population of Canada 2023\\\"\n",
      "\tObservation: Canada ranks 37th by population among countries of the world, comprising about 0.5% of the world's total, with 40 million Canadians as of 2023.\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"I now know the final answer\n",
      "\tFinal Answer: As of 2023, there are approximately 40 million people living in Canada.\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"I now know the final answer\n",
      "\tFinal Answer: As of 2023, there are approximately 40 million people living in Canada.\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 27,\n",
      "\t      \"prompt_tokens\": 256,\n",
      "\t      \"total_tokens\": 283\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: As of 2023, there are approximately 40 million people living in Canada.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As of 2023, there are approximately 40 million people living in Canada.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d28d73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\tHuman: How many people live in canada as of 2023?\n",
      "\tAI: As of 2023, there are approximately 40 million people living in Canada.\n",
      "\t\n",
      "\tNew question: how about in mexico?\n",
      "\t\",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Thought: I need to find the current population of Mexico.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"current population of Mexico\\\"\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Thought: I need to find the current population of Mexico.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"current population of Mexico\\\"\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 25,\n",
      "\t      \"prompt_tokens\": 206,\n",
      "\t      \"total_tokens\": 231\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the current population of Mexico.\n",
      "Action: Search\n",
      "Action Input: \"current population of Mexico\"\u001b[0m\n",
      "\t# SerpAPIWrapper.run started\n",
      "\n",
      "\t## Query: current population of Mexico\n",
      "\n",
      "\t## Results: {'type': 'population_result\n",
      "\n",
      "\t\tplace': 'Mexico\n",
      "\n",
      "\t\tpopulation': '126.7 million\n",
      "\n",
      "\t\tyear': '2021'}\n",
      "\n",
      "\t# SerpAPIWrapper.run finished\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m{'type': 'population_result', 'place': 'Mexico', 'population': '126.7 million', 'year': '2021'}\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\tHuman: How many people live in canada as of 2023?\n",
      "\tAI: As of 2023, there are approximately 40 million people living in Canada.\n",
      "\t\n",
      "\tNew question: how about in mexico?\n",
      "\tThought: I need to find the current population of Mexico.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"current population of Mexico\\\"\n",
      "\tObservation: {'type': 'population_result', 'place': 'Mexico', 'population': '126.7 million', 'year': '2021'}\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"The current population of Mexico is 126.7 million as of 2021.\n",
      "\tFinal Answer: The current population of Mexico is 126.7 million.\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"The current population of Mexico is 126.7 million as of 2021.\n",
      "\tFinal Answer: The current population of Mexico is 126.7 million.\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 32,\n",
      "\t      \"prompt_tokens\": 266,\n",
      "\t      \"total_tokens\": 298\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThe current population of Mexico is 126.7 million as of 2021.\n",
      "Final Answer: The current population of Mexico is 126.7 million.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current population of Mexico is 126.7 million.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"how about in mexico?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62356eed",
   "metadata": {},
   "source": [
    "## Knowledge base\n",
    "\n",
    "Create a custom vectorstore for the Agent to use as a tool to answer questions with. We'll store the results in [Pinecone](https://docs.pinecone.io/docs/quickstart), which is supported by LangChain ([Docs](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html), [API reference](https://python.langchain.com/en/latest/reference/modules/vectorstore.html)). For help getting started with Pinecone or other vector databases, we have a [cookbook](https://github.com/openai/openai-cookbook/blob/colin/examples/vector_databases/Using_vector_databases_for_embeddings_search.ipynb) to help you get started.\n",
    "\n",
    "You can check the LangChain documentation to see what other [vectorstores](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html) and [databases](https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html) are available.\n",
    "\n",
    "For this example we'll use the transcripts of the Stuff You Should Know podcast, which was provided thanks to OSF DOI [10.17605/OSF.IO/VM9NT](https://doi.org/10.17605/OSF.IO/VM9NT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f86008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "# Here is a URL to a zip archive containing the transcribed podcasts\n",
    "# Note that this data has already been split into chunks and embeddings from OpenAI's text-embedding-ada-002 embedding model are included\n",
    "content_url = 'https://cdn.openai.com/API/examples/data/sysk_podcast_transcripts_embedded.json.zip'\n",
    "\n",
    "# Download the file (it is ~541 MB so this will take some time)\n",
    "wget.download(content_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load podcasts\n",
    "with zipfile.ZipFile(\"sysk_podcast_transcripts_embedded.json.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8561b9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a6d4ea7d794597942cebadf7c66903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38145 [00:00<?, ?lines/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ijson\n",
    "\n",
    "processed_podcasts = []\n",
    "\n",
    "file_path = './data/sysk_podcast_transcripts_embedded.json'\n",
    "progress_lines = tqdm(total=38145, unit='lines')\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    items = ijson.items(f, 'item')\n",
    "    while True:\n",
    "        try:\n",
    "            item = next(items)\n",
    "            processed_podcasts.append(item)\n",
    "            progress_lines.update()\n",
    "        except StopIteration as e:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ceb572",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1070ef60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text_chunk</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cleaned_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>\\n\\nSYSK Selects How Crime Scene Cleanup Works</td>\n",
       "      <td>https://chtbl.com/track/5899E/podtrac.com/pts/...</td>\n",
       "      <td>Title: sysk_with_transcripts_SYSK Selects How ...</td>\n",
       "      <td>[0.021279960870742798, -0.005817972123622894, ...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>\\n\\nSYSK Selects How Crime Scene Cleanup Works</td>\n",
       "      <td>https://chtbl.com/track/5899E/podtrac.com/pts/...</td>\n",
       "      <td>Title: sysk_with_transcripts_SYSK Selects How ...</td>\n",
       "      <td>[0.013859338127076626, 0.00857278611510992, 0....</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>\\n\\nSYSK Selects How Crime Scene Cleanup Works</td>\n",
       "      <td>https://chtbl.com/track/5899E/podtrac.com/pts/...</td>\n",
       "      <td>Title: sysk_with_transcripts_SYSK Selects How ...</td>\n",
       "      <td>[0.015242221765220165, 0.016030369326472282, 0...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>\\n\\nSYSK Selects How Crime Scene Cleanup Works</td>\n",
       "      <td>https://chtbl.com/track/5899E/podtrac.com/pts/...</td>\n",
       "      <td>Title: sysk_with_transcripts_SYSK Selects How ...</td>\n",
       "      <td>[0.004371842369437218, -0.003036574460566044, ...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "      <td>\\n\\nSYSK Selects How Crime Scene Cleanup Works</td>\n",
       "      <td>https://chtbl.com/track/5899E/podtrac.com/pts/...</td>\n",
       "      <td>Title: sysk_with_transcripts_SYSK Selects How ...</td>\n",
       "      <td>[0.017309172078967094, 0.015154214575886726, 0...</td>\n",
       "      <td>sysk_with_transcripts_SYSK Selects How Crime S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "1  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "2  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "3  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "4  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "\n",
       "                                            filename  \\\n",
       "0  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "1  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "2  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "3  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "4  sysk_with_transcripts_SYSK Selects How Crime S...   \n",
       "\n",
       "                                            title  \\\n",
       "0  \\n\\nSYSK Selects How Crime Scene Cleanup Works   \n",
       "1  \\n\\nSYSK Selects How Crime Scene Cleanup Works   \n",
       "2  \\n\\nSYSK Selects How Crime Scene Cleanup Works   \n",
       "3  \\n\\nSYSK Selects How Crime Scene Cleanup Works   \n",
       "4  \\n\\nSYSK Selects How Crime Scene Cleanup Works   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://chtbl.com/track/5899E/podtrac.com/pts/...   \n",
       "1  https://chtbl.com/track/5899E/podtrac.com/pts/...   \n",
       "2  https://chtbl.com/track/5899E/podtrac.com/pts/...   \n",
       "3  https://chtbl.com/track/5899E/podtrac.com/pts/...   \n",
       "4  https://chtbl.com/track/5899E/podtrac.com/pts/...   \n",
       "\n",
       "                                          text_chunk  \\\n",
       "0  Title: sysk_with_transcripts_SYSK Selects How ...   \n",
       "1  Title: sysk_with_transcripts_SYSK Selects How ...   \n",
       "2  Title: sysk_with_transcripts_SYSK Selects How ...   \n",
       "3  Title: sysk_with_transcripts_SYSK Selects How ...   \n",
       "4  Title: sysk_with_transcripts_SYSK Selects How ...   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.021279960870742798, -0.005817972123622894, ...   \n",
       "1  [0.013859338127076626, 0.00857278611510992, 0....   \n",
       "2  [0.015242221765220165, 0.016030369326472282, 0...   \n",
       "3  [0.004371842369437218, -0.003036574460566044, ...   \n",
       "4  [0.017309172078967094, 0.015154214575886726, 0...   \n",
       "\n",
       "                                          cleaned_id  \n",
       "0  sysk_with_transcripts_SYSK Selects How Crime S...  \n",
       "1  sysk_with_transcripts_SYSK Selects How Crime S...  \n",
       "2  sysk_with_transcripts_SYSK Selects How Crime S...  \n",
       "3  sysk_with_transcripts_SYSK Selects How Crime S...  \n",
       "4  sysk_with_transcripts_SYSK Selects How Crime S...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the contents\n",
    "pd.DataFrame(processed_podcasts).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9715d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the text embeddings to Pinecone\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "def to_float(x):\n",
    "    return [float(y) for y in x]\n",
    "\n",
    "for i in tqdm(range(0, len(processed_podcasts), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(processed_podcasts), i+batch_size)\n",
    "    meta_batch = processed_podcasts[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['cleaned_id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text_chunk'] for x in meta_batch]\n",
    "    # add embeddings\n",
    "    embeds = [to_float(x['embedding']) for x in meta_batch]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'filename': x['filename'],\n",
    "        'title': x['title'],\n",
    "        'text_chunk': x['text_chunk'],\n",
    "        'url': x['url']\n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c5bac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the embeddings to be used by our retriever to be OpenAI Embeddings, matching our embedded corpus\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "# Loads a docsearch object from an existing Pinecone index so we can retrieve from it\n",
    "docsearch = Pinecone.from_existing_index(index_name,embeddings,text_key='text_chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dd21d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8abd34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_docs = retriever.get_relevant_documents(\"can you live without a bank account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "016bd458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: sysk: Can You Live Without a Bank Account?\n",
      "\n",
      "Title: sysk_with_transcripts_Can you live without a bank account.json;  And if you had a life, you didn't necessarily rectify your bank checkbook every day. Oh, wait, what is balancing a checkbook mean? Seriously? Yeah. Thank God for my wife. So another reason you might avoid a bank is philosophically. There may be a longstanding distrust of banks in your family that you don't want to put your money in, or you may just want to be like, you know what? I don't want to take part in this modern society. I want to kind of drop out a bit. And a really good first move is to shut your bank account down. That's a big statement. Oh, yeah, it is. But a lot of people that are underbanked and don't have accounts aren't there on purpose. It's not some philosophical statement. A lot of times it's simply because they are poor and they don't have a lot of alternatives. Yeah. And the other thing about not having a bank account, not only do you not have a bank account, you also are, like, basically just avoiding banks altogether. There's plenty of other things that banks offer, like loans and mortgage, lollipops, stuff like that. Yeah. Maybe some free nasty coffee. So when you don't have a banking account, that's like the most basic unit of the banking world. Right. If you don't have that, you obviously aren't going to be exposed to all these other things that can help. Things like build your credit history through like a revolving loan or a mortgage or a car loan or something like that that you can build up your credit for and ultimately save money. So when you don't have a bank account, for whatever reason, you are effectively out of the banking system. The problem is you can live parallel to the banking system outside of it, but it can be really dangerous, especially if you're just dealing with cash, because that cash has to stay somewhere, whether it's on you or in your mattress or in a coffee can in your backyard. You're exposed for having that readily available to anybody who finds it or comes into your house with a gun to get it. Yes.\n",
      "\n",
      "\n",
      "Title: sysk: Can You Live Without a Bank Account?\n",
      "\n",
      "Title: sysk_with_transcripts_Can you live without a bank account.json;  And it doesn't have to be an everyday thing. You can host when you want. Like, let's say you're taking a week's vacation. Why not host your home? Because that money could go toward paying for your current vacation or towards your retirement fund or even towards your kids college fund. Yeah. For anything. And listen, if you're worried about your stuff, don't be. Air cover for hosts. Let hosts welcome guests into their home without having to worry. You get $1 million in damage protection anytime you're hosting. Plus pet damage protection and income loss protection, too. And are you ready for this? Air cover for host is completely free every time you host on airbnb. Free with a capital F, with air cover for Host. It makes hosting a no brainer, and the benefits really start adding up. So learn more and host with peace of mind at Airbnb comaircoverforhosts. Capital One offers commercial solutions you can bank on. Now more than ever, your business faces specific challenges and unique opportunities. That's why Capital One offers a comprehensive suite of financial services custom tailored to your short and long term goals, backed by the expertise, strategy and resources of a top ten commercial bank, a dedicated team works with you to support your success and help you achieve your goals. Explore the possibilities at CapitalOne. comCOMMERCIAL all right, so if you live in modern society today, it is pretty tough to get by without a bank. Most cases these days you have well, I don't know about most cases, but in many cases you have automatic deposits of your work checks. Sure. A lot of people pay their bills wirelessly, online, directly from their bank. You might have a student loan, you might have a car loan, you might have your house mortgage, you might pay your credit card bills. All this stuff is running through a bank, most likely. And you would think it's probably impossible to not have a bank account these days. And I would say pretty much all Americans have them. Not true. Well, pretty much all Americans do. Like 93% do. Yeah, but that's not all. No, it's true.\n",
      "\n",
      "\n",
      "Title: sysk: Can You Live Without a Bank Account?\n",
      "\n",
      "Title: sysk_with_transcripts_Can you live without a bank account.json;  Yeah. 7% of Americans do not have bank accounts. About 9 million people last year in 2015 did not have bank accounts. 9 million people is a lot of people. No, it really is. And apparently that's household sorry, not people. Yeah, right. You're that is a big distinction, too. And the FDIC said, man, that's the lowest since we've been tracking this by far. And someone said, well, how long have you been tracking this? They said, well, the last six years. Really? Yeah, which I'm like. Really? That's when they started tracking it, but apparently so 2009. So if you want another number, the 9 million American households don't have bank accounts at all, then there are 25 million households in addition to that. So that makes almost like 34 million households, which that's a substantial number at this point. Sure. The 25 million are what's called underbanked, meaning they may have a bank account, but they don't use the bank account. Yeah. They don't use it because they are probably afraid of overdraft fees. Or they have maybe a bank account that got grandfathered in so that they don't have to pay minimum amount fees. And who knows? There's all sorts of reasons for people to not use a bank account that they have, but probably cheap among them is overdressed, which you'll talk more about. Yeah. And the majority of these underbank people in the United States are poor, usually. A lot of times they're minorities, a lot of times they're less educated. And these communities, there's a few reasons why they may not want to use a bank one. Maybe they don't trust banks. And if you look in the history of the United States or certainly even we're just talking about the Wells Fargo scandal, when you see stuff like that on the news, it should be upsetting to everyone. But obviously if you're poor and you don't have a lot of money, that may scare you into not wanting to use a bank at all. Right? Yeah.\n",
      "\n",
      "\n",
      "Title: sysk: Can You Live Without a Bank Account?\n",
      "\n",
      "Title: sysk_with_transcripts_Can you live without a bank account.json;  Maybe at the time, I might be making it up. I seem to remember them saying that, and I was like, I don't want that. Just let the check bounce and I'll take it up with them. Yes. The way it was marketed, though, was like, hey, we value you. We want to make sure that you can pay all your bills. So if something happens and you're overdrafted we'll cover it. We're just going to charge you a fee. And it sounds good, but again, when you go from high to low and all of a sudden your overdraft fees go from one to four or five or however many, that's a huge problem. Well, and the people that are overdrafting and the people that are at least able to afford those fees. Exactly. So it's a disproportionate burden on the poor, which makes it, as a scam, one of the more evil scams around. Yes. It's just wrong, then the idea that if you open an account, you should not opt in for overdraft protection. And it's easy to say when you're talking about checks for, like you're writing a check for a Mountain Dew and some cheetos. Yeah, who cares if you're short for that? You can go without that. But when you're talking about your rent check or like an actual grocery bill or something like that, it sucks that you can't get that stuff. But it's better to have to put a couple of things back than to pay $35 for one $2 item that you went over by, right? Yeah, that's a good point. And this was in my case, too. This is also back in the day when you I mean, a lot of times it was a mystery how much you had in your account. Right. Like, you couldn't just get on your phone before you write the check and be like, oh, well, no, I don't have enough money to cover this. Yeah, because even if you balanced your checkbook, sometimes you forgot to carry the one, it wasn't always 100% accurate.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the title and content for the most relevant retrieved documents\n",
    "print(\"\\n\".join(['Title: ' + x.metadata['title'].strip() + '\\n\\n' + x.page_content + '\\n\\n' for x in query_docs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf10f53",
   "metadata": {},
   "source": [
    "## LLM Agent with Tools\n",
    "\n",
    "Extend our list of tools by creating a [RetrievalQA](https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html) chain leveraging our Pinecone knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6cae4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retrieval_llm = OpenAI(temperature=0)\n",
    "\n",
    "podcast_retriever = RetrievalQA.from_chain_type(llm=retrieval_llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cc282cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = 'Knowledge Base',\n",
    "        func=podcast_retriever.run,\n",
    "        description=\"Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1e12121",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Re-initialize the agent with our new list of tools\n",
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=expanded_tools,\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)\n",
    "multi_tool_names = [tool.name for tool in expanded_tools]\n",
    "multi_tool_agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=multi_tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ac8eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_tool_memory = ConversationBufferWindowMemory(k=2)\n",
    "multi_tool_executor = AgentExecutor.from_agent_and_tools(agent=multi_tool_agent, tools=expanded_tools, verbose=True, memory=multi_tool_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f27bb1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\tKnowledge Base: Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search, Knowledge Base]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\t\n",
      "\t\n",
      "\tNew question: Hi, I'd like to know how you can live without a bank account\n",
      "\t\",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Thought: This is a general question about how to live without a bank account. It falls under the category of \\\"how to do things\\\" and can be answered using the Knowledge Base.\n",
      "\t\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: How can you live without a bank account?\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Thought: This is a general question about how to live without a bank account. It falls under the category of \\\"how to do things\\\" and can be answered using the Knowledge Base.\n",
      "\t\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: How can you live without a bank account?\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 54,\n",
      "\t      \"prompt_tokens\": 214,\n",
      "\t      \"total_tokens\": 268\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThought: This is a general question about how to live without a bank account. It falls under the category of \"how to do things\" and can be answered using the Knowledge Base.\n",
      "\n",
      "Action: Knowledge Base\n",
      "Action Input: How can you live without a bank account?\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m You can live without a bank account by using prepaid credit cards, hosting on Airbnb, and avoiding banks altogether. However, this can be dangerous as you are exposed to having your cash stolen or taken from you.\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\tKnowledge Base: Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search, Knowledge Base]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\t\n",
      "\t\n",
      "\tNew question: Hi, I'd like to know how you can live without a bank account\n",
      "\tThought: This is a general question about how to live without a bank account. It falls under the category of \\\"how to do things\\\" and can be answered using the Knowledge Base.\n",
      "\t\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: How can you live without a bank account?\n",
      "\tObservation:  You can live without a bank account by using prepaid credit cards, hosting on Airbnb, and avoiding banks altogether. However, this can be dangerous as you are exposed to having your cash stolen or taken from you.\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Living without a bank account can be challenging, but it is possible. However, it is important to note that this approach comes with certain risks and limitations. Here's what I found in the Knowledge Base:\n",
      "\t\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: What are the alternatives to having a bank account?\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Living without a bank account can be challenging, but it is possible. However, it is important to note that this approach comes with certain risks and limitations. Here's what I found in the Knowledge Base:\n",
      "\t\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: What are the alternatives to having a bank account?\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 59,\n",
      "\t      \"prompt_tokens\": 317,\n",
      "\t      \"total_tokens\": 376\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mLiving without a bank account can be challenging, but it is possible. However, it is important to note that this approach comes with certain risks and limitations. Here's what I found in the Knowledge Base:\n",
      "\n",
      "Action: Knowledge Base\n",
      "Action Input: What are the alternatives to having a bank account?\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb to make extra money, and using an alternative currency.\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\tKnowledge Base: Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search, Knowledge Base]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\t\n",
      "\t\n",
      "\tNew question: Hi, I'd like to know how you can live without a bank account\n",
      "\tThought: This is a general question about how to live without a bank account. It falls under the category of \\\"how to do things\\\" and can be answered using the Knowledge Base.\n",
      "\t\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: How can you live without a bank account?\n",
      "\tObservation:  You can live without a bank account by using prepaid credit cards, hosting on Airbnb, and avoiding banks altogether. However, this can be dangerous as you are exposed to having your cash stolen or taken from you.\n",
      "\tThought: Living without a bank account can be challenging, but it is possible. However, it is important to note that this approach comes with certain risks and limitations. Here's what I found in the Knowledge Base:\n",
      "\t\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: What are the alternatives to having a bank account?\n",
      "\tObservation:  Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb to make extra money, and using an alternative currency.\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Based on the information from the Knowledge Base, it seems that there are several alternatives to having a bank account. These alternatives include using prepaid credit cards, hosting on Airbnb to make extra money, and using alternative currencies. However, it is important to consider the risks and limitations associated with living without a bank account, such as the potential for cash theft or loss. \n",
      "\t\n",
      "\tFinal Answer: Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb, and using alternative currencies. However, living without a bank account can be challenging and comes with certain risks and limitations.\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Based on the information from the Knowledge Base, it seems that there are several alternatives to having a bank account. These alternatives include using prepaid credit cards, hosting on Airbnb to make extra money, and using alternative currencies. However, it is important to consider the risks and limitations associated with living without a bank account, such as the potential for cash theft or loss. \n",
      "\t\n",
      "\tFinal Answer: Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb, and using alternative currencies. However, living without a bank account can be challenging and comes with certain risks and limitations.\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 116,\n",
      "\t      \"prompt_tokens\": 409,\n",
      "\t      \"total_tokens\": 525\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mBased on the information from the Knowledge Base, it seems that there are several alternatives to having a bank account. These alternatives include using prepaid credit cards, hosting on Airbnb to make extra money, and using alternative currencies. However, it is important to consider the risks and limitations associated with living without a bank account, such as the potential for cash theft or loss. \n",
      "\n",
      "Final Answer: Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb, and using alternative currencies. However, living without a bank account can be challenging and comes with certain risks and limitations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb, and using alternative currencies. However, living without a bank account can be challenging and comes with certain risks and limitations.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_tool_executor.run(\"Hi, I'd like to know how you can live without a bank account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cba815cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\tKnowledge Base: Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search, Knowledge Base]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\tHuman: Hi, I'd like to know how you can live without a bank account\n",
      "\tAI: Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb, and using alternative currencies. However, living without a bank account can be challenging and comes with certain risks and limitations.\n",
      "\t\n",
      "\tNew question: Can you tell me some interesting facts about whether zoos are good or bad for animals\n",
      "\t\",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Thought: I should search for information about the pros and cons of zoos to provide a balanced answer.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"pros and cons of zoos for animals\\\"\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Thought: I should search for information about the pros and cons of zoos to provide a balanced answer.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"pros and cons of zoos for animals\\\"\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 39,\n",
      "\t      \"prompt_tokens\": 276,\n",
      "\t      \"total_tokens\": 315\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThought: I should search for information about the pros and cons of zoos to provide a balanced answer.\n",
      "Action: Search\n",
      "Action Input: \"pros and cons of zoos for animals\"\u001b[0m\n",
      "\t# SerpAPIWrapper.run started\n",
      "\n",
      "\t## Query: pros and cons of zoos for animals\n",
      "\n",
      "\t## Results: [\"Con 1. Zoos don't educate the public enough to justify\n",
      "\t\t keeping animals captive. ; Con 2. Zoos are detrimental\n",
      "\t\t to animals' physical health. ; Con 3. Zoo ...\", 'Ultimately\n",
      "\t\t, zoos provide an affordable opportunity to see (exotic\n",
      "\t\t) animals, giving everyone an equal chance to experience\n",
      "\t\t wildlife first-hand ...\n",
      "\n",
      "\t\tZoos educate the public about animals and conservation\n",
      "\t\t efforts. · Zoos educate the public about animals and\n",
      "\t\t conservation efforts. · Zoos save ...\n",
      "\n",
      "\t\tCons: Animal welfare: Some zoos have been criticized\n",
      "\t\t for poor living conditions, inadequate space, and\n",
      "\t\t lack of stimulation, which can lead to ...\n",
      "\n",
      "\t\t1. Zoos provide an educational resource. · 2. A zoo\n",
      "\t\t provides a protected environment for endangered animals\n",
      "\t\t. · 3. Zoos can provide a place for the ...\n",
      "\n",
      "\t\tWhile zoo advocates and conservationists argue that\n",
      "\t\t zoos save endangered species and educate the public\n",
      "\t\t, many animal rights activists believe the cost of\n",
      "\t\t ...\n",
      "\n",
      "\t\tDisadvantages of Zoos · Animals are trapped in unnatural\n",
      "\t\t environments · Conditions in zoos are often rather\n",
      "\t\t poor · Animals often only have quite limited space\n",
      "\t\t ...\n",
      "\n",
      "\t\tAnimal cruelty or protection? Learn about the pros\n",
      "\t\t and cons of zoos and join our debate and poll: Should\n",
      "\t\t there be zoos? Should animals be kept in captivity\n",
      "\t\t?', \"Zoo's are good for some animals. I say keep the\n",
      "\t\t ones that live well in captivity and take care of\n",
      "\t\t the injured and endangered ones for some ...\"]\n",
      "\n",
      "\t# SerpAPIWrapper.run finished\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m[\"Con 1. Zoos don't educate the public enough to justify keeping animals captive. ; Con 2. Zoos are detrimental to animals' physical health. ; Con 3. Zoo ...\", 'Ultimately, zoos provide an affordable opportunity to see (exotic) animals, giving everyone an equal chance to experience wildlife first-hand ...', 'Zoos educate the public about animals and conservation efforts. · Zoos educate the public about animals and conservation efforts. · Zoos save ...', 'Cons: Animal welfare: Some zoos have been criticized for poor living conditions, inadequate space, and lack of stimulation, which can lead to ...', '1. Zoos provide an educational resource. · 2. A zoo provides a protected environment for endangered animals. · 3. Zoos can provide a place for the ...', 'While zoo advocates and conservationists argue that zoos save endangered species and educate the public, many animal rights activists believe the cost of ...', 'Disadvantages of Zoos · Animals are trapped in unnatural environments · Conditions in zoos are often rather poor · Animals often only have quite limited space ...', 'Animal cruelty or protection? Learn about the pros and cons of zoos and join our debate and poll: Should there be zoos? Should animals be kept in captivity?', \"Zoo's are good for some animals. I say keep the ones that live well in captivity and take care of the injured and endangered ones for some ...\"]\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\tKnowledge Base: Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search, Knowledge Base]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\tHuman: Hi, I'd like to know how you can live without a bank account\n",
      "\tAI: Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb, and using alternative currencies. However, living without a bank account can be challenging and comes with certain risks and limitations.\n",
      "\t\n",
      "\tNew question: Can you tell me some interesting facts about whether zoos are good or bad for animals\n",
      "\tThought: I should search for information about the pros and cons of zoos to provide a balanced answer.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"pros and cons of zoos for animals\\\"\n",
      "\tObservation: [\\\"Con 1. Zoos don't educate the public enough to justify keeping animals captive. ; Con 2. Zoos are detrimental to animals' physical health. ; Con 3. Zoo ...\\\", 'Ultimately, zoos provide an affordable opportunity to see (exotic) animals, giving everyone an equal chance to experience wildlife first-hand ...', 'Zoos educate the public about animals and conservation efforts. \\u00b7 Zoos educate the public about animals and conservation efforts. \\u00b7 Zoos save ...', 'Cons: Animal welfare: Some zoos have been criticized for poor living conditions, inadequate space, and lack of stimulation, which can lead to ...', '1. Zoos provide an educational resource. \\u00b7 2. A zoo provides a protected environment for endangered animals. \\u00b7 3. Zoos can provide a place for the ...', 'While zoo advocates and conservationists argue that zoos save endangered species and educate the public, many animal rights activists believe the cost of ...', 'Disadvantages of Zoos \\u00b7 Animals are trapped in unnatural environments \\u00b7 Conditions in zoos are often rather poor \\u00b7 Animals often only have quite limited space ...', 'Animal cruelty or protection? Learn about the pros and cons of zoos and join our debate and poll: Should there be zoos? Should animals be kept in captivity?', \\\"Zoo's are good for some animals. I say keep the ones that live well in captivity and take care of the injured and endangered ones for some ...\\\"]\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"I have found a variety of perspectives on the pros and cons of zoos. I should provide a balanced answer by including both the positive and negative aspects.\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: \\\"Are zoos good or bad for animals?\\\"\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"I have found a variety of perspectives on the pros and cons of zoos. I should provide a balanced answer by including both the positive and negative aspects.\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: \\\"Are zoos good or bad for animals?\\\"\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 49,\n",
      "\t      \"prompt_tokens\": 622,\n",
      "\t      \"total_tokens\": 671\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mI have found a variety of perspectives on the pros and cons of zoos. I should provide a balanced answer by including both the positive and negative aspects.\n",
      "Action: Knowledge Base\n",
      "Action Input: \"Are zoos good or bad for animals?\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m It depends. Zoos have gotten a lot better in the last 30-40 years in terms of creating more natural habitats for animals and participating in research and conservation projects. However, animals in zoos often have shorter lifespans than those in the wild, and people may come out of zoos less informed than they were before. Additionally, some zoos still procure animals from the wild, which can be detrimental to threatened species.\u001b[0m\n",
      "\n",
      "\t# CustomChatOpenAi._generate started\n",
      "\n",
      "\t\t## Messages: \n",
      "\t\t{\n",
      "\t  \"content\": \"You are SearchGPT, a professional search engine who provides informative answers to users. \n",
      "\tAnswer the following questions as best you can. You have access to the following tools:\n",
      "\t\n",
      "\tSearch: useful for when you need to answer questions about current events\n",
      "\tKnowledge Base: Useful for general questions about how to do things and for details on interesting topics. Input should be a fully formed question.\n",
      "\t\n",
      "\tUse the following format:\n",
      "\t\n",
      "\tQuestion: the input question you must answer\n",
      "\tThought: you should always think about what to do\n",
      "\tAction: the action to take, should be one of [Search, Knowledge Base]\n",
      "\tAction Input: the input to the action\n",
      "\tObservation: the result of the action\n",
      "\t... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "\tThought: I now know the final answer\n",
      "\tFinal Answer: the final answer to the original input question\n",
      "\t\n",
      "\tBegin! Remember to give detailed, informative answers\n",
      "\t\n",
      "\tPrevious conversation history:\n",
      "\tHuman: Hi, I'd like to know how you can live without a bank account\n",
      "\tAI: Some alternatives to having a bank account include using prepaid credit cards, hosting on Airbnb, and using alternative currencies. However, living without a bank account can be challenging and comes with certain risks and limitations.\n",
      "\t\n",
      "\tNew question: Can you tell me some interesting facts about whether zoos are good or bad for animals\n",
      "\tThought: I should search for information about the pros and cons of zoos to provide a balanced answer.\n",
      "\tAction: Search\n",
      "\tAction Input: \\\"pros and cons of zoos for animals\\\"\n",
      "\tObservation: [\\\"Con 1. Zoos don't educate the public enough to justify keeping animals captive. ; Con 2. Zoos are detrimental to animals' physical health. ; Con 3. Zoo ...\\\", 'Ultimately, zoos provide an affordable opportunity to see (exotic) animals, giving everyone an equal chance to experience wildlife first-hand ...', 'Zoos educate the public about animals and conservation efforts. \\u00b7 Zoos educate the public about animals and conservation efforts. \\u00b7 Zoos save ...', 'Cons: Animal welfare: Some zoos have been criticized for poor living conditions, inadequate space, and lack of stimulation, which can lead to ...', '1. Zoos provide an educational resource. \\u00b7 2. A zoo provides a protected environment for endangered animals. \\u00b7 3. Zoos can provide a place for the ...', 'While zoo advocates and conservationists argue that zoos save endangered species and educate the public, many animal rights activists believe the cost of ...', 'Disadvantages of Zoos \\u00b7 Animals are trapped in unnatural environments \\u00b7 Conditions in zoos are often rather poor \\u00b7 Animals often only have quite limited space ...', 'Animal cruelty or protection? Learn about the pros and cons of zoos and join our debate and poll: Should there be zoos? Should animals be kept in captivity?', \\\"Zoo's are good for some animals. I say keep the ones that live well in captivity and take care of the injured and endangered ones for some ...\\\"]\n",
      "\tThought: I have found a variety of perspectives on the pros and cons of zoos. I should provide a balanced answer by including both the positive and negative aspects.\n",
      "\tAction: Knowledge Base\n",
      "\tAction Input: \\\"Are zoos good or bad for animals?\\\"\n",
      "\tObservation:  It depends. Zoos have gotten a lot better in the last 30-40 years in terms of creating more natural habitats for animals and participating in research and conservation projects. However, animals in zoos often have shorter lifespans than those in the wild, and people may come out of zoos less informed than they were before. Additionally, some zoos still procure animals from the wild, which can be detrimental to threatened species.\n",
      "\tThought: \",\n",
      "\t  \"additional_kwargs\": {},\n",
      "\t  \"type\": \"human\",\n",
      "\t  \"example\": false\n",
      "\t}\n",
      "\n",
      "\t## Result: \n",
      "\t{\n",
      "\t  \"generations\": [\n",
      "\t    {\n",
      "\t      \"text\": \"Based on the information I found, the final answer is that the question of whether zoos are good or bad for animals is complex and depends on various factors. While zoos can provide educational opportunities, protected environments for endangered species, and contribute to conservation efforts, they also have drawbacks. Animals in zoos may experience poor living conditions, limited space, and lack of stimulation. Some zoos still obtain animals from the wild, which can harm threatened species. Additionally, animals in zoos often have shorter lifespans compared to those in the wild. Therefore, it is important to consider both the positive and negative aspects when evaluating the impact of zoos on animals.\",\n",
      "\t      \"generation_info\": {\n",
      "\t        \"finish_reason\": \"stop\"\n",
      "\t      },\n",
      "\t      \"type\": \"ChatGeneration\",\n",
      "\t      \"message\": {\n",
      "\t        \"content\": \"Based on the information I found, the final answer is that the question of whether zoos are good or bad for animals is complex and depends on various factors. While zoos can provide educational opportunities, protected environments for endangered species, and contribute to conservation efforts, they also have drawbacks. Animals in zoos may experience poor living conditions, limited space, and lack of stimulation. Some zoos still obtain animals from the wild, which can harm threatened species. Additionally, animals in zoos often have shorter lifespans compared to those in the wild. Therefore, it is important to consider both the positive and negative aspects when evaluating the impact of zoos on animals.\",\n",
      "\t        \"additional_kwargs\": {},\n",
      "\t        \"type\": \"ai\",\n",
      "\t        \"example\": false\n",
      "\t      }\n",
      "\t    }\n",
      "\t  ],\n",
      "\t  \"llm_output\": {\n",
      "\t    \"token_usage\": {\n",
      "\t      \"completion_tokens\": 133,\n",
      "\t      \"prompt_tokens\": 765,\n",
      "\t      \"total_tokens\": 898\n",
      "\t    },\n",
      "\t    \"model_name\": \"gpt-3.5-turbo\",\n",
      "\t    \"system_fingerprint\": null\n",
      "\t  }\n",
      "\t}\n",
      "\n",
      "\t# CustomChatOpenAi._generate finished\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not parse LLM output: `Based on the information I found, the final answer is that the question of whether zoos are good or bad for animals is complex and depends on various factors. While zoos can provide educational opportunities, protected environments for endangered species, and contribute to conservation efforts, they also have drawbacks. Animals in zoos may experience poor living conditions, limited space, and lack of stimulation. Some zoos still obtain animals from the wild, which can harm threatened species. Additionally, animals in zoos often have shorter lifespans compared to those in the wild. Therefore, it is important to consider both the positive and negative aspects when evaluating the impact of zoos on animals.`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmulti_tool_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCan you tell me some interesting facts about whether zoos are good or bad for animals\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/langchain/chains/base.py:507\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    508\u001b[0m         _output_key\n\u001b[1;32m    509\u001b[0m     ]\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    513\u001b[0m         _output_key\n\u001b[1;32m    514\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/langchain/chains/base.py:312\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    313\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    314\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    315\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    316\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/langchain/chains/base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    299\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    300\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    301\u001b[0m     inputs,\n\u001b[1;32m    302\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    303\u001b[0m )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 306\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    311\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/langchain/agents/agent.py:1312\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1312\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1321\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1322\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/langchain/agents/agent.py:1038\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1031\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1036\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1038\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1048\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/langchain/agents/agent.py:1038\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1031\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1036\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1038\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1048\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/langchain/agents/agent.py:1066\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1066\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/openai-cookbook/lib/python3.11/site-packages/langchain/agents/agent.py:537\u001b[0m, in \u001b[0;36mLLMSingleActionAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \n\u001b[1;32m    522\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    532\u001b[0m     intermediate_steps\u001b[38;5;241m=\u001b[39mintermediate_steps,\n\u001b[1;32m    533\u001b[0m     stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop,\n\u001b[1;32m    534\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    536\u001b[0m )\n\u001b[0;32m--> 537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m, in \u001b[0;36mCustomOutputParser.parse\u001b[0;34m(self, llm_output)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# If it can't parse the output it raises an error\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# You can add your own logic here to handle errors in a different way i.e. pass to a human, give a canned response\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m action \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     23\u001b[0m action_input \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not parse LLM output: `Based on the information I found, the final answer is that the question of whether zoos are good or bad for animals is complex and depends on various factors. While zoos can provide educational opportunities, protected environments for endangered species, and contribute to conservation efforts, they also have drawbacks. Animals in zoos may experience poor living conditions, limited space, and lack of stimulation. Some zoos still obtain animals from the wild, which can harm threatened species. Additionally, animals in zoos often have shorter lifespans compared to those in the wild. Therefore, it is important to consider both the positive and negative aspects when evaluating the impact of zoos on animals.`"
     ]
    }
   ],
   "source": [
    "multi_tool_executor.run('Can you tell me some interesting facts about whether zoos are good or bad for animals')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe408a3",
   "metadata": {},
   "source": [
    "You now have a template to deploy conversational agents with tools. If you want to extend this with a Custom Agent to add your own retry behaviour or treatment of input/output variables, then follow [this article](https://python.langchain.com/en/latest/modules/agents/agents/custom_agent.html).\n",
    "\n",
    "We look forward to seeing what you build!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
